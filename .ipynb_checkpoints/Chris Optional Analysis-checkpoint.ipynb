{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.axes as axes\n",
    "import datetime\n",
    "from scipy import stats\n",
    "from scipy.stats import ttest_ind\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "sns.set_palette('colorblind')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "biden = pd.read_csv(\"biden_tweets.csv\")\n",
    "trump = pd.read_csv(\"trump_tweets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('trump', 796), ('president', 737), ('donald', 499), ('nation', 346), ('american', 335), ('country', 306), ('people', 289), ('day', 271), ('time', 241), ('crisis', 220), ('care', 214), ('health', 212), ('help', 211), ('together', 207), ('today', 206), ('america', 197), ('americans', 183), ('work', 176), ('years', 175), ('going', 171), ('white', 170), ('back', 168), ('know', 157), ('campaign', 151), ('better', 148), ('house', 143), ('covid-19', 142), ('world', 137), ('like', 137), ('must', 134)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter \n",
    "from string import punctuation\n",
    "  \n",
    "allbidenwords = \"\"\n",
    "\n",
    "#concatenate texts in all of biden's post into one string, making them all lowercase\n",
    "for i in range(len(biden)):\n",
    "    allbidenwords+=biden['full_text'][i].lower()\n",
    "\n",
    "#transforms the concatenated string into a list of all the words in the string\n",
    "allbidenwords2 = allbidenwords.split()\n",
    "\n",
    "#download the nltk packages – action required running this code: go to Corpora, and download \"stopwords\"\n",
    "import nltk\n",
    "\n",
    "#nltk.download() <--unhighlight this code to do the installation\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#obtain the english stopwords\n",
    "\n",
    "stopwords = stopwords.words('english')\n",
    "\n",
    "#create and add our own list of english stopwords\n",
    "\n",
    "additionalstopwords=['',\"—\",\"-\",\"need\",\"get\",\"make\",\"every\",\"one\",\"us\",\"take\",\"it’s\",\"it.\",\"we're\",\"i'll\",\"i'm\",\"let\",\"can't\"]\n",
    "\n",
    "for i in range(len(additionalstopwords)):\n",
    "    stopwords.append(additionalstopwords[i])\n",
    "    \n",
    "#remove all leading and trailing punctuations of biden's words\n",
    "for i in range(len(allbidenwords2)):\n",
    "    allbidenwords2[i]=allbidenwords2[i].strip(punctuation)\n",
    "    \n",
    "#create a new counter object which we will use to count the words and their frequencies\n",
    "\n",
    "Counter = Counter(allbidenwords2) \n",
    "\n",
    "#returns the top-200 (leave a large enough margin) most freqeunt words and their count\n",
    "bidenmostfrequentwords = Counter.most_common(200)\n",
    "\n",
    "#filter out the english stopwords from the list of words\n",
    "\n",
    "bidenmostfrequentwords = [(word, count) for word, count in bidenmostfrequentwords if word not in stopwords]\n",
    "  \n",
    "#print only the top-30 most frequent words and their count\n",
    "print(bidenmostfrequentwords[:30]) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat the same procedure for Trump:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('great', 200), ('amp', 194), ('biden', 131), ('people', 120), ('joe', 99), ('news', 94), ('fake', 88), ('never', 84), ('would', 78), ('vote', 78), ('country', 74), ('big', 73), ('even', 71), ('total', 70), ('democrats', 69), ('president', 69), ('many', 65), ('left', 64), ('like', 61), ('going', 61), ('new', 61), ('want', 60), ('back', 60), ('complete', 59), ('maga', 58), ('endorsement', 58), ('thank', 57), ('years', 56), ('state', 56), ('election', 56)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter \n",
    "from string import punctuation\n",
    "\n",
    "alltrumpwords = \"\"\n",
    "\n",
    "#concatenate texts in all of trump's post into one string, making them all lowercase\n",
    "for i in range(len(trump)):\n",
    "    alltrumpwords+=trump['full_text'][i].lower()\n",
    "\n",
    "#transforms the concatenated string into a list of all the words in the string\n",
    "alltrumpwords2 = alltrumpwords.split()\n",
    "\n",
    "#download the nltk packages – action required running this code: go to Corpora, and download \"stopwords\"\n",
    "import nltk\n",
    "\n",
    "#nltk.download() <--unhighlight this code to do the installation\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#obtain the english stopwords\n",
    "\n",
    "stopwords = stopwords.words('english')\n",
    "\n",
    "#create and add our own list of english stopwords\n",
    "\n",
    "additionalstopwords=['',\"—\",\"-\",\"need\",\"get\",\"make\",\"every\",\"one\",\"us\",\"take\",\"it’s\",\"it.\",\"we're\",\"i'll\",\"i'm\",\"let\",\"can't\"]\n",
    "\n",
    "for i in range(len(additionalstopwords)):\n",
    "    stopwords.append(additionalstopwords[i])\n",
    "    \n",
    "#remove all leading and trailing punctuations of trump's words\n",
    "for i in range(len(alltrumpwords2)):\n",
    "    alltrumpwords2[i]=alltrumpwords2[i].strip(punctuation)\n",
    "    \n",
    "#create a new counter object which we will use to count the words and their frequencies\n",
    "\n",
    "Counter = Counter(alltrumpwords2) \n",
    "\n",
    "#returns the top-200 (leave a large enough margin) most freqeunt words and their count\n",
    "trumpmostfrequentwords = Counter.most_common(200)\n",
    "\n",
    "#filter out the english stopwords from the list of words\n",
    "\n",
    "trumpmostfrequentwords = [(word, count) for word, count in trumpmostfrequentwords if word not in stopwords]\n",
    "  \n",
    "#print only the top-30 most frequent words and their count\n",
    "print(trumpmostfrequentwords[:30])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
