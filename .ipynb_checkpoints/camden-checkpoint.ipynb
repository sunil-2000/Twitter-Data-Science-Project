{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\camde\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## load libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(phrase):\n",
    "    '''\n",
    "    Returns an array of individual words in the string phrase\n",
    "    phrase: The string to be tokenized\n",
    "    '''\n",
    "    tokens = nltk.word_tokenize(phrase)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                   id  \\\n",
      "0           0  1313663334286323714   \n",
      "1           1  1313652765319557122   \n",
      "2           2  1313646473393840128   \n",
      "3           3  1313641691602202624   \n",
      "4           4  1313633890289045504   \n",
      "\n",
      "                                           full_text  \\\n",
      "0                    Please. https://t.co/acHR1Rf8hE   \n",
      "1  I can’t wait for @KamalaHarris to make history...   \n",
      "2  Ignore the polls, folks. There’s too much at s...   \n",
      "3  Think about what it takes for a Black person t...   \n",
      "4  Look, folks, I'm going to be honest: we'll try...   \n",
      "\n",
      "                                            entities           created_at  \\\n",
      "0  {'hashtags': [], 'symbols': [], 'user_mentions...  2020-10-07 02:12:00   \n",
      "1  {'hashtags': [], 'symbols': [], 'user_mentions...  2020-10-07 01:30:00   \n",
      "2  {'hashtags': [], 'symbols': [], 'user_mentions...  2020-10-07 01:05:00   \n",
      "3  {'hashtags': [], 'symbols': [], 'user_mentions...  2020-10-07 00:46:00   \n",
      "4  {'hashtags': [], 'symbols': [], 'user_mentions...  2020-10-07 00:15:00   \n",
      "\n",
      "   favourite  retweets language  geo  in_reply  \n",
      "0      90289     14867       en  NaN       NaN  \n",
      "1      13317      2126       en  NaN       NaN  \n",
      "2      56278     12104       en  NaN       NaN  \n",
      "3      30592      6574       en  NaN       NaN  \n",
      "4      13490      3023       en  NaN       NaN  \n",
      "Number of tweets: 3084\n"
     ]
    }
   ],
   "source": [
    "#Load Biden's tweets\n",
    "biden_tweets = pd.read_csv(\"biden_tweets.csv\")\n",
    "number_of_biden_tweets = len(biden_tweets.index) #Number of tweets we collected\n",
    "print(biden_tweets.head())\n",
    "print(\"Number of tweets: \" + str(number_of_biden_tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Biden words tweeted: 123036\n",
      "Mean number of words in each Biden tweet: 39.89494163424124\n",
      "Median number of words in each Biden tweet: 43.0\n",
      "Mode number of words in each Biden tweet: 48\n",
      "The least number of words Biden used in a tweet was: 2\n",
      "The most number of words Biden used in a tweet was: 72\n",
      "Standard deviation of number of words in each Biden tweet: 14.67815065696819\n"
     ]
    }
   ],
   "source": [
    "# Summary stats for the full_text column\n",
    "biden_total_words = 0 # The number of words Biden used across all the Tweets we collected\n",
    "biden_word_counts_list = [] # A list of the word count for each tweet\n",
    "for tweet in biden_tweets[\"full_text\"]:\n",
    "    tweet_length = len(tokenize(tweet))\n",
    "    biden_word_counts_list.append(tweet_length)                 \n",
    "    biden_total_words += tweet_length\n",
    "print(\"Biden words tweeted: \" + str(biden_total_words))\n",
    "biden_mean_wordcount = np.mean(biden_word_counts_list) #Mean number of words in each of Biden's tweets\n",
    "print(\"Mean number of words in each Biden tweet: \" + str(biden_mean_wordcount))\n",
    "biden_median_wordcount = np.median(biden_word_counts_list)\n",
    "print(\"Median number of words in each Biden tweet: \" + str(biden_median_wordcount))\n",
    "biden_mode_wordcount = statistics.mode(biden_word_counts_list)\n",
    "print(\"Mode number of words in each Biden tweet: \" + str(biden_mode_wordcount))\n",
    "biden_minimum_words = min(biden_word_counts_list)\n",
    "print(\"The least number of words Biden used in a tweet was: \" + str(biden_minimum_words))\n",
    "biden_maximum_words = max(biden_word_counts_list)\n",
    "print(\"The most number of words Biden used in a tweet was: \" + str(biden_maximum_words))\n",
    "biden_stddev_wordcount = np.std(biden_word_counts_list)\n",
    "print(\"Standard deviation of number of words in each Biden tweet: \" + str(biden_stddev_wordcount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
